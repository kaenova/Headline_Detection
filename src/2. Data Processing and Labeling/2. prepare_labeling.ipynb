{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Labeling\n",
    "We're going to get ~2500 data with ~1250 of organization and the replies.  \n",
    "For the organization data we're going to get the most replied and every tweet by organization we're going to search the most liked reply.\n",
    "Also, we're going to create the labeling datasets stepwise operation.\n",
    "There' will be 5 batch of labeling datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're going to get 53 tweets for every organization and reply for every step\n"
     ]
    }
   ],
   "source": [
    "data_csv = [\"CNNIndonesia.csv\", \"detikcom.csv\", \"tvOneNews.csv\", \"VIVAcoid.csv\"]\n",
    "NUM_ORGANIZTION = len(data_csv)\n",
    "NUM_TARGET_DATA = 1250\n",
    "NUM_STEP = 6\n",
    "NUM_TWEET_ORGANIZATION = int(np.ceil((1250 / NUM_ORGANIZTION) / NUM_STEP)) \n",
    "\n",
    "relative_path_data = \"../../data/2. Filtered/\"\n",
    "organization_path = f\"{relative_path_data}/organization\"\n",
    "replies_path = f\"{relative_path_data}/replies\"\n",
    "relative_path_data_labeling = \"../../data/3. Labeling Ready/\"\n",
    "\n",
    "organizaton_df = {data: pd.read_csv(f\"{organization_path}/{data}\")\\\n",
    "                          .sort_values(\"reply_count\", ascending=False).reset_index(drop=True)\n",
    "                 for data in data_csv}\n",
    "replies_df = {data: pd.read_csv(f\"{replies_path}/{data}\") \\\n",
    "                      .sort_values(\"like_count\", ascending=False)\\\n",
    "                      .set_index(\"tweet_conversation_id\", drop=False)\n",
    "              for data in data_csv}\n",
    "\n",
    "print(f\"We're going to get {NUM_TWEET_ORGANIZATION} tweets for every organization and reply for every step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id 1584812873498431488 has no met min char reply\n",
      "org 13 rep 13\n",
      "org 13 rep 13\n",
      "org 13 rep 13\n",
      "org 13 rep 13\n",
      "Conversation id 1594570082688307200 has no met min char reply\n",
      "Conversation id 1520691882736578560 has no met min char reply\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "Conversation id 1596357377241980928 has no met min char reply\n",
      "Conversation id 1585932086648741890 has no met min char reply\n",
      "Conversation id 1573728607855583232 has no met min char reply\n",
      "Conversation id 1603350165657890818 has no met min char reply\n",
      "Conversation id 1584018158532583425 has no met min char reply\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "Conversation id 1577226192608198656 has no met min char reply\n",
      "Conversation id 1587611213454008322 has no met min char reply\n",
      "Conversation id 1567703786650738688 has no met min char reply\n",
      "Conversation id 1584205646098235394 has no met min char reply\n",
      "Conversation id 1601079346793689093 has no met min char reply\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "Conversation id 1581210663229456384 has no met min char reply\n",
      "Conversation id 1580058499467603968 has no met min char reply\n",
      "Conversation id 1600602659865694233 has no met min char reply\n",
      "Conversation id 1588405114661896192 has no met min char reply\n",
      "Conversation id 1584400128521416706 has no met min char reply\n",
      "Conversation id 1608658427949076481 has no met min char reply\n",
      "Conversation id 1493129644979097602 has no met min char reply\n",
      "Conversation id 1559542277566976001 has no met min char reply\n",
      "Conversation id 1565629398191308800 has no met min char reply\n",
      "Conversation id 1583232902628007936 has no met min char reply\n",
      "Conversation id 1518091376793055233 has no met min char reply\n",
      "Conversation id 1511222871665782793 has no met min char reply\n",
      "Conversation id 1564515802552082432 has no met min char reply\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "Conversation id 1579376316813438976 has no met min char reply\n",
      "Conversation id 1582051753310138370 has no met min char reply\n",
      "Conversation id 1596797747880927232 has no met min char reply\n",
      "Conversation id 1532997351631073282 has no met min char reply\n",
      "Conversation id 1605700919592898563 has no met min char reply\n",
      "Conversation id 1589793968552054785 has no met min char reply\n",
      "Conversation id 1597471433726517248 has no met min char reply\n",
      "Conversation id 1576802765887922176 has no met min char reply\n",
      "Conversation id 1574922349488775173 has no met min char reply\n",
      "Conversation id 1576441997090787328 has no met min char reply\n",
      "Conversation id 1584679018632458240 has no met min char reply\n",
      "Conversation id 1585988518220025859 has no met min char reply\n",
      "Conversation id 1581784446029950976 has no met min char reply\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n",
      "org 53 rep 53\n"
     ]
    }
   ],
   "source": [
    "# Build Labeling data\n",
    "# A minimum character for a reply. If there's no reply that have met the min char go get the first one  most likedf_\n",
    "MIN_CHAR = 100\n",
    "columns_removed = [\"reply_count\", \"like_count\", \"tweet_url\"]\n",
    "\n",
    "# We want to have sample for the first one (total data: 100 on every organization)\n",
    "# If NUM_TWEET_ORGANIZATION has 53 on 1 organization and our target is 100 on every organization\n",
    "# We should divide X / 2\n",
    "NUM_SAMPLE_TWEET_ORGANIZATION = NUM_TWEET_ORGANIZATION // 2\n",
    "\n",
    "for step in range(1, NUM_STEP + 1):\n",
    "    start_index = NUM_SAMPLE_TWEET_ORGANIZATION + NUM_TWEET_ORGANIZATION * (step - 1)\n",
    "    end_index = NUM_SAMPLE_TWEET_ORGANIZATION + NUM_TWEET_ORGANIZATION * step\n",
    "\n",
    "    if step == 1:\n",
    "        start_index = 0\n",
    "        end_index = NUM_SAMPLE_TWEET_ORGANIZATION\n",
    "\n",
    "    organization_labeling_df = {}\n",
    "    reply_labeling_df = {}\n",
    "    for data_name in data_csv:\n",
    "        current_organization = organizaton_df[data_name].copy()\n",
    "        current_replies = replies_df[data_name].copy()\n",
    "\n",
    "        # Get the headline data\n",
    "        current_organization = current_organization[start_index:end_index]\n",
    "\n",
    "        # Get the reply data by matching tweet_id and conversation_id\n",
    "        conversation_ids = current_organization[\"tweet_id\"].values\n",
    "        replies = []\n",
    "        for conversation_id in conversation_ids:\n",
    "            all_replies = current_replies.loc[conversation_id]\n",
    "\n",
    "            # Only got one reply\n",
    "            if isinstance(all_replies, pd.Series):\n",
    "                replies.append(all_replies)\n",
    "                continue\n",
    "\n",
    "            # Got multiple reply\n",
    "            if isinstance(all_replies, pd.DataFrame):\n",
    "                appended_reply = all_replies.iloc[0]\n",
    "\n",
    "                min_char_met = False\n",
    "                for i in range(len(all_replies)):\n",
    "                    current_reply = all_replies.iloc[i]\n",
    "                    if len(current_reply[\"tweet\"]) > MIN_CHAR:\n",
    "                        appended_reply = current_reply\n",
    "                        min_char_met = True\n",
    "                        break\n",
    "\n",
    "                if not min_char_met:\n",
    "                    print(\n",
    "                        f\"Conversation id {conversation_id} has no met min char reply\"\n",
    "                    )\n",
    "\n",
    "                replies.append(all_replies.iloc[0])\n",
    "                continue\n",
    "\n",
    "            print(f\"No Reply detected on conversation_id {conversation_id}\")\n",
    "\n",
    "        organization_labeling_df[data_name] = current_organization.copy()\n",
    "        reply_labeling_df[data_name] = pd.DataFrame(replies).reset_index(drop=True)\n",
    "\n",
    "    # Save data\n",
    "    # Combine for labeling\n",
    "    df_organization = []\n",
    "    df_replies = []\n",
    "    for i in organization_labeling_df:\n",
    "        print(f\"org {len(organization_labeling_df[i])} rep {len(reply_labeling_df[i])}\")\n",
    "        df_organization.append(organization_labeling_df[i])\n",
    "        df_replies.append(reply_labeling_df[i])\n",
    "\n",
    "    concat_org = pd.concat(df_organization)\n",
    "    concat_org[\"labels (Non-Headline 0 / Headline 1)\"] = np.ones(len(concat_org)) * -1\n",
    "    concat_rep = pd.concat(df_replies)\n",
    "    concat_rep[\"labels (Non-Headline 0 / Headline 1)\"] = np.ones(len(concat_org)) * -1\n",
    "\n",
    "    concat_org = concat_org.drop(columns=columns_removed)\n",
    "    concat_rep = concat_rep.drop(columns=columns_removed)\n",
    "\n",
    "    with pd.ExcelWriter(\n",
    "        f\"{relative_path_data_labeling}/organization_{step}.xlsx\", engine=\"openpyxl\"\n",
    "    ) as writer:\n",
    "        concat_org.to_excel(writer, sheet_name=\"Organization Sheet\", index=False)\n",
    "\n",
    "    with pd.ExcelWriter(\n",
    "        f\"{relative_path_data_labeling}/replies_{MIN_CHAR}_{step}.xlsx\",\n",
    "        engine=\"openpyxl\",\n",
    "    ) as writer:\n",
    "        concat_rep.to_excel(writer, sheet_name=\"Replies Sheet\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f859f1e6f927a99659bbed8c715d8b2e0ee62a381a7a8caee1b1f662fc1c2ad7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
