{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Google Colab Environement and build handmade library\n",
    "!git clone https://github.com/kaenova/Headline_Detection.git\n",
    "%cd \"/content/Headline_Detection\"\n",
    "\n",
    "!make lib-install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reset Google Colab Environment\n",
    "# %cd ..\n",
    "# !rm -fr Headline_Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Custom handmade library\n",
    "import kaelib.processor.preprocessing_func as prep_func\n",
    "from kaelib.processor import TextProcessingPipeline\n",
    "from kaelib.model import  FastTextClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset google-play-review (C:/Users/kaeno/.cache/huggingface/datasets/jakartaresearch___google-play-review/default/1.0.0/df84e67f495cc6639ab0bbf74ff0190498a0b22294fdaca26a5b25e090671c29)\n",
      "100%|██████████| 2/2 [00:00<00:00, 667.40it/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"jakartaresearch/google-play-review\")\n",
    "data_train = data.get('train').to_pandas()[['text', 'label']]\n",
    "data_test = data.get('validation').to_pandas()[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Halo\\n blibli. Sedikit saran untuk gratis ong...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So far so good. Respon cepat.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thank</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aplikasi sering not responding di hp saya (as...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gak ada komentar.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0   Halo\\n blibli. Sedikit saran untuk gratis ong...   pos\n",
       "1                      So far so good. Respon cepat.   pos\n",
       "2                                              thank   neg\n",
       "3   Aplikasi sering not responding di hp saya (as...   neg\n",
       "4                                  Gak ada komentar.   pos"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "text_train = data_train[\"text\"].values.tolist()\n",
    "text_test = data_test[\"text\"].values.tolist()\n",
    "\n",
    "label2id = {\"pos\": 1, \"neg\": 0}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "labels_train = data_train[\"label\"].apply(lambda x: label2id[x]).values.tolist()\n",
    "labels_test = data_test[\"label\"].apply(lambda x: label2id[x]).values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep text\n",
    "pipeline = TextProcessingPipeline([\n",
    "    prep_func.lowercasing,\n",
    "    prep_func.remove_html_tags,\n",
    "    prep_func.remove_url,\n",
    "    prep_func.remove_punctuation\n",
    "])\n",
    "\n",
    "X_train = pipeline.process_corpus(text_train)\n",
    "X_test = pipeline.process_corpus(text_test)\n",
    "\n",
    "y_train = labels_train[:]\n",
    "y_test = labels_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching function\n",
    "# https://stackoverflow.com/questions/8290397/how-to-split-an-iterable-in-constant-size-chunks\n",
    "from itertools import islice\n",
    "\n",
    "def batcher(iterable, batch_size):\n",
    "    iterator = iter(iterable)\n",
    "    while batch := list(islice(iterator, batch_size)):\n",
    "        yield batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH 1 / 10: 100%|██████████| 110/110 [00:25<00:00,  4.26it/s, loss=0.3267, loss_test=0.3207, metric_test=0.6134]\n",
      "EPOCH 2 / 10: 100%|██████████| 110/110 [00:25<00:00,  4.27it/s, loss=0.2664, loss_test=0.2707, metric_test=0.7766]\n",
      "EPOCH 3 / 10: 100%|██████████| 110/110 [00:26<00:00,  4.19it/s, loss=0.2513, loss_test=0.2661, metric_test=0.7897]\n",
      "EPOCH 4 / 10: 100%|██████████| 110/110 [00:27<00:00,  3.96it/s, loss=0.2434, loss_test=0.2636, metric_test=0.7957]\n",
      "EPOCH 5 / 10: 100%|██████████| 110/110 [00:26<00:00,  4.20it/s, loss=0.2434, loss_test=0.2687, metric_test=0.7941]\n",
      "EPOCH 6 / 10: 100%|██████████| 110/110 [00:25<00:00,  4.25it/s, loss=0.2393, loss_test=0.2694, metric_test=0.7959]\n",
      "EPOCH 7 / 10: 100%|██████████| 110/110 [00:24<00:00,  4.44it/s, loss=0.2348, loss_test=0.2689, metric_test=0.7985]\n",
      "EPOCH 8 / 10: 100%|██████████| 110/110 [00:24<00:00,  4.47it/s, loss=0.2318, loss_test=0.2696, metric_test=0.7996]\n",
      "EPOCH 9 / 10: 100%|██████████| 110/110 [00:26<00:00,  4.14it/s, loss=0.2297, loss_test=0.2703, metric_test=0.8000]\n",
      "EPOCH 10 / 10: 100%|██████████| 110/110 [00:25<00:00,  4.28it/s, loss=0.2250, loss_test=0.2699, metric_test=0.7999]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "device = \"cpu\"\n",
    "lr = 0.05\n",
    "\n",
    "num_mini_batch = math.ceil(len(X_train) / batch_size)\n",
    "\n",
    "model = FastTextClassifier().to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "metrics = MulticlassAccuracy(2).to(device)\n",
    "\n",
    "# Allocate some test tensor\n",
    "target_test = torch.tensor(y_test, dtype=torch.int64, device=device)\n",
    "\n",
    "for i in range(epochs):\n",
    "    batch_generator_text = batcher(X_train, batch_size)\n",
    "    batch_generator_label = batcher(y_train, batch_size)\n",
    "\n",
    "    epoch_loss = []\n",
    "    epoch_loss_test = []\n",
    "    epoch_metrics_test = []\n",
    "\n",
    "    with tqdm(total=num_mini_batch) as pbar:\n",
    "        pbar.set_description(f\"EPOCH {i + 1} / {epochs}\")\n",
    "        \n",
    "        for j in range(num_mini_batch):\n",
    "            model.zero_grad()\n",
    "            # Prepare data\n",
    "            mini_batch_text = next(batch_generator_text)\n",
    "            mini_batch_labels = next(batch_generator_label)\n",
    "            target = torch.tensor(mini_batch_labels, dtype=torch.int64, device=device)\n",
    "\n",
    "            # Forward\n",
    "            pred = model(mini_batch_text)\n",
    "            loss = F.cross_entropy(pred, target)\n",
    "            # Backprop\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            # Forward test\n",
    "            with torch.no_grad():\n",
    "                pred_test = model(X_test)\n",
    "                loss_test = F.cross_entropy(pred_test, target_test)\n",
    "                metrics_test = metrics(pred_test, target_test)\n",
    "\n",
    "            # Metrics and logging\n",
    "            epoch_loss.append(loss.item())\n",
    "            avg_loss = sum(epoch_loss) / len(epoch_loss)\n",
    "\n",
    "            epoch_loss_test.append(loss_test.item())\n",
    "            avg_loss_test = sum(epoch_loss_test) / len(epoch_loss_test)\n",
    "            epoch_metrics_test.append(metrics_test.item())\n",
    "            avg_metric_test = sum(epoch_metrics_test) / len(epoch_metrics_test)\n",
    "\n",
    "            pbar.set_postfix(\n",
    "                {\n",
    "                    \"loss\": f\"{avg_loss:.4f}\",\n",
    "                    \"loss_test\": f\"{avg_loss_test:.4f}\",\n",
    "                    \"metric_test\": f\"{avg_metric_test:.4f}\",\n",
    "                }\n",
    "            )\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aku suka aplikasi ini' : pos\n",
      "'tidak suka sama aplikasi ini' : neg\n",
      "'oke' : pos\n",
      "'keren aplikasi' : pos\n",
      "'malu pake aplikasi ini' : neg\n"
     ]
    }
   ],
   "source": [
    "test_input = [\"aku suka aplikasi ini\", \"tidak suka sama aplikasi ini\", \"oke\", \"keren aplikasi\", \"malu pake aplikasi ini\"]\n",
    "with torch.no_grad():\n",
    "    pred = model(test_input)\n",
    "    pred = F.softmax(pred, dim=1)\n",
    "    pred_np = pred.argmax(dim=1).cpu().detach().numpy()\n",
    "    for i in range(len(test_input)):\n",
    "        print(f\"'{test_input[i]}' : {id2label[pred_np[i]]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f859f1e6f927a99659bbed8c715d8b2e0ee62a381a7a8caee1b1f662fc1c2ad7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
