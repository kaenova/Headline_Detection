{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Google Colab Environement and build handmade library\n",
    "# !git clone https://github.com/kaenova/Headline_Detection.git\n",
    "# %cd \"/content/Headline_Detection\"\n",
    "\n",
    "# !make lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reset Google Colab Environment\n",
    "# %cd ..\n",
    "# !rm -fr Headline_Detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Custom handmade library\n",
    "from kaelib.processor import TextProcessingPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d03c8a386e248a3aa05fc1ca545dfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361b60a4d51041fd96a84fdad6da38d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b74d3bec8e47bf8b448aaa7c8f2a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset google-play-review (C:/Users/kaeno/.cache/huggingface/datasets/jakartaresearch___google-play-review/default/1.0.0/df84e67f495cc6639ab0bbf74ff0190498a0b22294fdaca26a5b25e090671c29)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7ef28e204b457ebb15d25c05b63e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"jakartaresearch/google-play-review\")\n",
    "data_train = data.get('train').to_pandas()[['text', 'label']]\n",
    "data_test = data.get('validation').to_pandas()[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Halo\\n blibli. Sedikit saran untuk gratis ong...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So far so good. Respon cepat.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thank</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aplikasi sering not responding di hp saya (as...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gak ada komentar.</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0   Halo\\n blibli. Sedikit saran untuk gratis ong...   pos\n",
       "1                      So far so good. Respon cepat.   pos\n",
       "2                                              thank   neg\n",
       "3   Aplikasi sering not responding di hp saya (as...   neg\n",
       "4                                  Gak ada komentar.   pos"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "text_train = data_train[\"text\"].values.tolist()\n",
    "text_test = data_test[\"text\"].values.tolist()\n",
    "\n",
    "label2id = {\"pos\": 1, \"neg\": 0}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "labels_train = data_train[\"label\"].apply(lambda x: label2id[x]).values.tolist()\n",
    "labels_test = data_test[\"label\"].apply(lambda x: label2id[x]).values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import typing\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x: \"list[str]\",\n",
    "        y: \"list[int]\",\n",
    "        preprocessor: \"typing.Optional[TextProcessingPipeline]\" = None,\n",
    "    ):\n",
    "        assert len(x) == len(y)\n",
    "        self.x = x\n",
    "        self.y = torch.tensor(y)\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def _process_idx_text(self, idx):\n",
    "        data = self.x[idx]\n",
    "        if type(idx) is not slice:\n",
    "            data = [self.x[idx]]\n",
    "        if self.preprocessor is not None:\n",
    "            data = self.preprocessor.process_corpus(data)\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        processed_corpus = self._process_idx_text(idx)\n",
    "        return processed_corpus, self.y[idx]\n",
    "\n",
    "train_dataset = TextClassificationDataset(text_train, labels_train)\n",
    "test_dataset = TextClassificationDataset(text_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/1607.01759.pdf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchnlp.word_to_vector import FastText\n",
    "import lightning.pytorch as pl\n",
    "from torchmetrics.classification import F1Score, Accuracy\n",
    "\n",
    "\n",
    "class FastTextClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seq_length: \"int\" = 256,\n",
    "        out_feature: \"int\" = 2,\n",
    "        pad_sequence: \"bool\" = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.pad_sequence = pad_sequence\n",
    "        self.fasttext = FastText(\"id\")\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(300, 150),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(150, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, out_feature),\n",
    "        )\n",
    "        self.f1_scorer = F1Score(task=\"multiclass\", num_classes=out_feature)\n",
    "        self.accuracy_scorer = Accuracy(task=\"multiclass\", num_classes=out_feature)\n",
    "\n",
    "    def _forward_fasttext(self, x: \"list[str]\"):\n",
    "        batch_text_embedding = torch.tensor([]).to(self.device)\n",
    "        for sentence in x:\n",
    "            sentence_seq = sentence.split(\" \")\n",
    "            if len(sentence_seq) > self.seq_length:\n",
    "                sentence_seq = sentence_seq[: self.seq_length]\n",
    "            if self.pad_sequence:\n",
    "                while len(sentence_seq) < 256:\n",
    "                    sentence_seq.append(\"<pad>\")\n",
    "            word_embedding = (\n",
    "                self.fasttext[sentence_seq].mean(dim=0).unsqueeze(0).to(self.device)\n",
    "            )\n",
    "            batch_text_embedding = torch.cat((batch_text_embedding, word_embedding))\n",
    "        return batch_text_embedding\n",
    "\n",
    "    def forward(self, x: \"list[str]\") -> \"torch.Tensor\":\n",
    "        # Prepare str\n",
    "        logits: torch.Tensor = self._forward_fasttext(x)\n",
    "        logits = self.feed_forward(logits)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, y = batch\n",
    "        pred = self.forward(x[0])\n",
    "        loss = F.cross_entropy(pred, y)\n",
    "        self.log(\"training_loss\", loss)\n",
    "        f1_score = self.f1_scorer(pred, y)\n",
    "        self.log(\"training_f1\", f1_score, prog_bar=True)\n",
    "        accuracy = self.accuracy_scorer(pred, y)\n",
    "        self.log(\"training_accuracy\", accuracy, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, y = batch\n",
    "        pred = self.forward(x[0])\n",
    "        loss = F.cross_entropy(pred, y)\n",
    "        self.log(\"validation_loss\", loss)\n",
    "        f1_score = self.f1_scorer(pred, y)\n",
    "        self.log(\"validation_f1\", f1_score, prog_bar=True)\n",
    "        accuracy = self.accuracy_scorer(pred, y)\n",
    "        self.log(\"validation_accuracy\", accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, y = batch\n",
    "        pred = self.forward(x[0])\n",
    "        loss = F.cross_entropy(pred, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        f1_score = self.f1_scorer(pred, y)\n",
    "        self.log(\"validation_f1\", f1_score, prog_bar=True)\n",
    "        accuracy = self.accuracy_scorer(pred, y)\n",
    "        self.log(\"validation_accuracy\", accuracy, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.00001)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FastTextClassifier()\n",
    "model(['test','halo']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type               | Params\n",
      "-------------------------------------------------------\n",
      "0 | feed_forward    | Sequential         | 54.9 K\n",
      "1 | f1_scorer       | MulticlassF1Score  | 0     \n",
      "2 | accuracy_scorer | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------------\n",
      "54.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "54.9 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ecb4087d8645f9bdc35920f1a0536a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c3a808f22b41db9280ce4077b21203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef487143af564e16a32bf866eb38e570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c960d49c476844d99dac6006925a70ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1779185792fc4a9288b38b9bc6ff7822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f9908d71da407389af6df6b1cae112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5605186223983765     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    validation_accuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8406374454498291     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       validation_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8406374454498291     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5605186223983765    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   validation_accuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8406374454498291    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      validation_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8406374454498291    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.5605186223983765,\n",
       "  'validation_f1': 0.8406374454498291,\n",
       "  'validation_accuracy': 0.8406374454498291}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "tb_log = TensorBoardLogger(\"tensorboard\", \"fasttext\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=50)\n",
    "validation_loader = DataLoader(test_dataset, batch_size=50)\n",
    "\n",
    "trainer = pl.Trainer(logger=tb_log)\n",
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=validation_loader)\n",
    "\n",
    "trainer.test(model=model, dataloaders=test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aku suka aplikasi ini' : pos\n",
      "'tidak suka sama aplikasi ini' : pos\n",
      "'oke' : pos\n",
      "'keren aplikasi' : pos\n",
      "'malu pake aplikasi ini' : neg\n"
     ]
    }
   ],
   "source": [
    "test_input = [\n",
    "    \"aku suka aplikasi ini\", \n",
    "    \"tidak suka sama aplikasi ini\", \n",
    "    \"oke\", \n",
    "    \"keren aplikasi\", \n",
    "    \"malu pake aplikasi ini\"\n",
    "]\n",
    "with torch.no_grad():\n",
    "    pred = model(test_input)\n",
    "    pred = F.softmax(pred, dim=1)\n",
    "    pred_np = pred.argmax(dim=1).cpu().detach().numpy()\n",
    "    for i in range(len(test_input)):\n",
    "        print(f\"'{test_input[i]}' : {id2label[pred_np[i]]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f859f1e6f927a99659bbed8c715d8b2e0ee62a381a7a8caee1b1f662fc1c2ad7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
